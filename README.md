# crawler
Just trying out some web crawling.

1. Interact with website to obtain parsed results
2. Determine which results show be acted upon
3. Download file, upload it to other service, delete downloaded file
4. Check for completed files from other service and copy to server in appropriate location
5. Profit?

PhantomJS must be installed prior to running
Configure it by customizing config.json and ssearch.json
Run main.py using Python 3
